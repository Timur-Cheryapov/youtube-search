"""
File I/O utilities for the YouTube crawler.

This module provides functions for saving and loading JSON data,
managing processed channels tracking, handling file operations,
and Supabase integration.
"""

import json
import logging
from typing import Dict, List, Optional
from datetime import datetime
try:
    from . import config
    from .supabase_client import create_supabase_client, SupabaseClient
except ImportError:
    import config
    from supabase_client import create_supabase_client, SupabaseClient

logger = logging.getLogger(__name__)


def save_to_json(data: Dict, filename: str):
    """Save data to JSON file with proper encoding"""
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def load_processed_channels() -> Dict:
    """Load the list of already processed channels"""
    try:
        with open(config.PROCESSED_CHANNELS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        logger.info("No processed_channels.json found, starting fresh")
        return {}
    except Exception as e:
        logger.error(f"Error loading processed channels: {e}")
        return {}


def save_processed_channels(processed_channels: Dict):
    """Save the list of processed channels"""
    try:
        with open(config.PROCESSED_CHANNELS_FILE, "w", encoding="utf-8") as f:
            json.dump(processed_channels, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error saving processed channels: {e}")


def is_channel_processed(channel_id: str, processed_channels: Dict) -> bool:
    """Check if a channel has already been processed"""
    return channel_id in processed_channels


def mark_channel_processed(channel_info: Dict, processed_channels: Dict, video_count: int):
    """Mark a channel as processed with metadata"""
    channel_id = channel_info['channel_id']
    processed_channels[channel_id] = {
        'channel_url': channel_info['channel_url'],
        'channel_name': channel_info['channel_name'],
        'found_via_query': channel_info['found_via_query'],
        'processed_date': datetime.now().isoformat(),
        'video_count': video_count,
        'status': 'processed'
    }


def save_results_with_fallback(all_results: Dict, filename: str) -> bool:
    """
    Save results with fallback to chunked saving if main save fails
    
    Returns:
        True if saved successfully, False otherwise
    """
    try:
        save_to_json(all_results, filename)
        logger.info(f"ğŸ’¾ Results saved to: {filename}")
        return True
    except Exception as e:
        logger.error(f"âŒ Failed to save main results: {e}")
        
        # Try to save smaller chunks if main save fails
        logger.info("ğŸ”§ Attempting to save results in smaller chunks...")
        try:
            chunk_size = max(1, len(all_results) // config.CHUNK_COUNT)
            chunks = list(all_results.items())
            
            for i in range(0, len(chunks), chunk_size):
                chunk = dict(chunks[i:i + chunk_size])
                chunk_file = f"{config.CHUNK_FILE_PREFIX}_{i//chunk_size + 1}.json"
                save_to_json(chunk, chunk_file)
                logger.info(f"ğŸ’¾ Saved chunk to: {chunk_file}")
            
            return True
        except Exception as chunk_error:
            logger.error(f"âŒ Failed to save chunks: {chunk_error}")
            return False


def save_periodic_backup(all_results: Dict, channel_count: int):
    """Save periodic backup of results"""
    try:
        backup_file = f"{config.BACKUP_FILE_PREFIX}_{channel_count}.json"
        save_to_json(all_results, backup_file)
        logger.info(f"ğŸ’¾ Periodic backup saved: {backup_file}")
    except Exception as e:
        logger.error(f"âŒ Failed to save periodic backup: {e}")


# New Supabase integration functions

def upload_channel_to_supabase(supabase_client: SupabaseClient, channel_info: Dict, videos: List[Dict]) -> bool:
    """Upload a channel's videos directly to Supabase"""
    try:
        channel_url = channel_info['channel_url']
        channel_name = channel_info['channel_name']
        
        logger.info(f"â¬†ï¸  Uploading {len(videos)} videos from {channel_name} to Supabase...")
        
        # Convert videos to Supabase documents
        documents = []
        skipped_count = 0
        
        for video in videos:
            document = supabase_client.create_document_from_video(video, channel_url)
            if document:
                documents.append(document)
            else:
                skipped_count += 1
        
        if skipped_count > 0:
            logger.warning(f"âš ï¸  Skipped {skipped_count} videos without embeddings")
        
        if not documents:
            logger.warning(f"âŒ No valid documents to upload for {channel_name}")
            return False
        
        # Upload documents in batches
        upload_result = supabase_client.upload_videos_batch(documents)
        
        # Save channel statistics immediately after successful upload
        if upload_result['success'] > 0:
            supabase_client.save_channel_stats(channel_info, upload_result['success'])
            logger.info(f"ğŸ“Š Updated channel stats for: {channel_info['channel_name']} ({upload_result['success']} videos)")
        else:
            logger.warning(f"âš ï¸  Skipping channel stats update - no videos uploaded successfully")
        
        success_rate = upload_result['success'] / upload_result['total'] if upload_result['total'] > 0 else 0
        logger.info(f"âœ… Uploaded {upload_result['success']}/{upload_result['total']} videos from {channel_name} ({success_rate:.1%} success rate)")
        
        return upload_result['success'] > 0
        
    except Exception as e:
        logger.error(f"âŒ Error uploading channel {channel_info['channel_name']} to Supabase: {e}")
        return False


def save_results_with_supabase_fallback(all_results: Dict, supabase_client: Optional[SupabaseClient], filename: str) -> bool:
    """
    Save results to Supabase if available, otherwise fall back to JSON files
    
    Args:
        all_results: Dictionary of channel_url -> videos
        supabase_client: Supabase client instance (None if disabled)
        filename: Fallback JSON filename
        
    Returns:
        True if saved successfully, False otherwise
    """
    if supabase_client:
        try:
            logger.info("ğŸ’¾ Saving results to Supabase database...")
            
            total_channels = len(all_results)
            total_videos = sum(len(videos) for videos in all_results.values())
            successful_channels = 0
            
            logger.info(f"ğŸ“Š Processing {total_channels} channels with {total_videos} total videos")
            
            for channel_url, videos in all_results.items():
                # Extract channel info from first video's source_channel
                if videos and 'source_channel' in videos[0]:
                    channel_info = videos[0]['source_channel']
                    channel_info['channel_url'] = channel_url  # Ensure URL is set
                    
                    if upload_channel_to_supabase(supabase_client, channel_info, videos):
                        successful_channels += 1
                else:
                    logger.warning(f"âš ï¸  Skipping channel {channel_url} - missing channel info")
            
            logger.info(f"ğŸ‰ Supabase upload complete: {successful_channels}/{total_channels} channels uploaded successfully")
            
            # Also save JSON backup for safety
            logger.info("ğŸ’¾ Saving JSON backup for safety...")
            return save_results_with_fallback(all_results, filename)
            
        except Exception as e:
            logger.error(f"âŒ Supabase upload failed: {e}")
            logger.info("ğŸ“ Falling back to JSON file save...")
            return save_results_with_fallback(all_results, filename)
    else:
        # No Supabase client - use JSON file mode
        logger.info("ğŸ“ Saving results to JSON file (Supabase disabled)")
        return save_results_with_fallback(all_results, filename)


def load_processed_channels_from_supabase(supabase_client: Optional[SupabaseClient]) -> Dict:
    """Load processed channels from Supabase or fall back to JSON file"""
    if supabase_client:
        try:
            processed_urls = supabase_client.get_processed_channels()
            
            # Convert to format expected by existing code
            processed_channels = {}
            unique_channels = 0
            
            for url in processed_urls:
                # Use URL as primary key
                channel_data = {
                    'channel_url': url,
                    'processed_from': 'supabase',
                    'status': 'processed'
                }
                processed_channels[url] = channel_data
                unique_channels += 1
                
                # Also add by channel_id for backward compatibility with JSON mode
                if url.startswith('https://www.youtube.com/channel/'):
                    channel_id = url.split('/')[-1]
                    processed_channels[channel_id] = channel_data  # Same object reference
            
            logger.info(f"ğŸ“– Loaded {unique_channels} processed channels from Supabase (with {len(processed_channels)} total lookup keys)")
            return processed_channels
            
        except Exception as e:
            logger.error(f"âŒ Error loading processed channels from Supabase: {e}")
            logger.info("ğŸ“ Falling back to JSON file...")
    
    # Fall back to JSON file
    return load_processed_channels()


def is_channel_processed_supabase(channel_url: str, supabase_client: Optional[SupabaseClient]) -> bool:
    """Check if channel is processed by querying the database directly"""
    if supabase_client:
        # Check database directly for channel existence
        return supabase_client.check_channel_processed(channel_url)
    
    # Fall back to JSON-based check (need to load processed channels first)
    processed_channels = load_processed_channels()
    if channel_url.startswith('https://www.youtube.com/channel/'):
        channel_id = channel_url.split('/')[-1]
        return is_channel_processed(channel_id, processed_channels)
    
    return False


def mark_channel_processed_supabase(channel_info: Dict, video_count: int, supabase_client: Optional[SupabaseClient]):
    """Mark channel as processed (channel stats should already be saved during upload for Supabase)"""
    if supabase_client:
        # For Supabase mode, channel stats are already saved during the upload process
        # via save_channel_stats() in the upload_channel_to_supabase function
        # No additional action needed since database is the source of truth
        logger.debug(f"ğŸ“ Channel {channel_info['channel_name']} already marked as processed during upload")
        return
    
    # Fall back to JSON file for non-Supabase mode
    processed_channels = load_processed_channels()
    mark_channel_processed(channel_info, processed_channels, video_count)
    save_processed_channels(processed_channels)